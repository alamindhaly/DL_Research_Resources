# -*- coding: utf-8 -*-
"""Copy of DeepLe_Skin_Cancer

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hpQgh7ngAp_b-XvYHcas0gds5fye4kyO
"""

import matplotlib.pyplot as plt
from keras.utils.np_utils import to_categorical
from keras.callbacks import ReduceLROnPlateau
import keras
from tensorflow.keras.optimizers import Adam 
from glob import glob
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
import cv2
import PIL
import seaborn as sns
import os
import numpy as np
import glob as gb



from google.colab import drive
drive.mount('/content/drive')

trainpath3 = '/content/drive/MyDrive/Datasets/archive/train/'
testpath13 = '/content/drive/MyDrive/Datasets/archive/test/'

new_size=224    
X_train = []
y_train = []
for folder in  os.listdir(trainpath3) : 
    print( 'folder name is : ', folder)
    files = gb.glob(pathname= str( trainpath3  + folder + '/*.jpg'))
    print( 'numbers of images in folder are : ', len(files))
    for file in files: 
        image_class = {'benign': 0, 'malignant': 1}
        orignal_image = cv2.imread(file)
        image = cv2.cvtColor(orignal_image, cv2.COLOR_BGR2RGB)
        resized_image = cv2.resize(image , (new_size,new_size))
        X_train.append(list(resized_image))
        y_train.append(image_class[folder])
print("items in X_train is:       ",len(X_train) , " items") 
print("items in y_train is:       ",len(y_train) , " items")

new_size=224    
X_test = []
y_test = []
for folder in  os.listdir(testpath13 ) : 
    print( 'folder name is : ', folder)
    files = gb.glob(pathname= str( testpath13  + folder + '/*.jpg'))
    print( 'numbers of images in folder are : ', len(files))
    for file in files: 
        image_class = {'benign': 0, 'malignant': 1}
        orignal_image = cv2.imread(file)
        image = cv2.cvtColor(orignal_image, cv2.COLOR_BGR2RGB)
        resized_image = cv2.resize(image , (new_size,new_size))
        X_test.append(list(resized_image))
        y_test.append(image_class[folder])
print("items in X_test is:       ",len(X_test) , " items")
print("items in y_test is:       ",len(y_test) , " items")

X_train = np.array(X_train)
y_train = np.array(y_train)
print("X_train shape  :" ,X_train.shape)
print("y_train shape :", y_train.shape)
X_test = np.array(X_test)
y_test = np.array(y_test)
print("X_test shape  :" ,X_test.shape)
print("y_test shape :", y_test.shape)

plt.bar(0, y_train[np.where(y_train == 0)].shape[0], label = 'benign')
plt.bar(1, y_train[np.where(y_train == 1)].shape[0], label = 'malignant')
plt.legend()
plt.title("Training Data")
plt.show()

plt.bar(0, y_test[np.where(y_test == 0)].shape[0], label = 'benign')
plt.bar(1, y_test[np.where(y_test == 1)].shape[0], label = 'malignant')
plt.legend()
plt.title("Test Data")
plt.show()

y_train = to_categorical(y_train, num_classes=2)
y_test = to_categorical(y_test, num_classes=2)
X_train = X_train/255
X_test = X_test/255

folders = glob('/content/drive/MyDrive/Deep_Learning/Dataset/train/*')

"""#**Inception** **V3**"""

from tensorflow.keras.applications.inception_v3 import InceptionV3

IMAGE_SIZE = [224, 224]
inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in inception.layers:
    layer.trainable = False

x = Flatten()(inception.output)
prediction = Dense(len(folders), activation='sigmoid')(x)

# create a model object
model = Model(inputs=inception.input, outputs=prediction)

model=model.add(Flatten())

model.compile(optimizer = 'adam',
             loss = 'binary_crossentropy',
             metrics=['accuracy'])

history = model.fit(X_train, y_train, validation_split=0.2,
                   epochs = 2,
                   batch_size = 32,
                   verbose = 1)

print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('InceptionV3 Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Inception V3 model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)

from sklearn import metrics

import pandas as pd

res = pd.DataFrame(columns=["Accuracy", 
                            "Precision", 
                            "Recall", 
                            "F1Score"])

ypred = model.predict(X_test)
y_pred = np.round(abs(ypred))
pr, rc, fs, sup = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')
res = res.append({"Accuracy": round(metrics.accuracy_score(y_test, y_pred), 4),"Precision": round(pr, 4), "Recall":round(rc, 4), "F1Score":round(fs, 4),}, ignore_index=True)
res.set_index("Accuracy", inplace=True)
res.sort_values(by="Accuracy", ascending=False, inplace=True)   
print(res)

"""#**VGG19**"""

from tensorflow.keras.applications.vgg19 import VGG19

vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in vgg.layers:
    layer.trainable = False

x1 = Flatten()(vgg.output)

x1= Flatten()(vgg.output)
prediction = Dense(len(folders), activation='sigmoid')(x1)

# create a model object
moddel1 = Model(inputs=vgg.input, outputs=prediction)

moddel1.compile(optimizer = 'adam',
             loss = 'binary_crossentropy',
             metrics=['accuracy'])

history1 = moddel1.fit(X_train, y_train, validation_split=0.2,
                   epochs = 2,
                   batch_size = 32,
                   verbose = 1)

print(history1.history.keys())
# summarize history for accuracy
plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.title('VGG19 Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.title('VGG19 model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

y_pred = moddel1.predict(X_test)
print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))

"""#**MobileNetV2**"""

from keras.applications.mobilenet_v2 import MobileNetV2
mobile = MobileNetV2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in mobile.layers:
    layer.trainable = False

x3 = Flatten()(mobile.output)

prediction = Dense(len(folders), activation='sigmoid')(x3)

model3 = Model(inputs=mobile.input, outputs=prediction)

model3.compile(optimizer = 'adam',
             loss = 'binary_crossentropy',
             metrics=['accuracy'])

history3 = model3.fit(X_train, y_train, validation_split=0.2,
                   epochs = 2,
                   batch_size = 32,
                   verbose = 1)

print(history3.history.keys())
# summarize history for accuracy
plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('MobileNetV2 Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('MobileNetV2 model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

y_pred3 = model3.predict(X_test)
print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred3, axis=1)))

"""#**EfficientNetB7**"""

from tensorflow.keras.applications import EfficientNetB7
effici = EfficientNetB7(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in effici.layers:
    layer.trainable = False

x4 = Flatten()(effici.output)

prediction4 = Dense(len(folders), activation='sigmoid')(x4)

model4 = Model(inputs=effici.input, outputs=prediction4)

model4.compile(optimizer = 'adam',
             loss = 'binary_crossentropy',
             metrics=['accuracy'])

history4 = model4.fit(X_train, y_train, validation_split=0.2,
                   epochs = 2,
                   batch_size = 32,
                   verbose = 1)

print(history4.history.keys())
# summarize history for accuracy
plt.plot(history4.history['accuracy'])
plt.plot(history4.history['val_accuracy'])
plt.title('EfficientNetB7 Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history4.history['loss'])
plt.plot(history4.history['val_loss'])
plt.title('EfficientNetB7 model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

y_pred4 = model4.predict(X_test)
print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred4, axis=1)))

"""#**Augmentation**"""

from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip(images_arr, axes):
        ax.imshow(img)
    plt.tight_layout()
    plt.show()

BATCH_SIZE = 100
IMG_SHAPE  = 150 # Our training data consists of images with width of 150 pixels and height of 150 pixels

image_gen_train = ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,
                                                     directory= trainpath3,
                                                     shuffle=True,
                                                     target_size=(IMG_SHAPE,IMG_SHAPE),
                                                     class_mode='binary')

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImages(augmented_images)



"""#**INCEPTION** **V31**"""

from tensorflow.keras.applications.inception_v3 import InceptionV3

IMAGE_SIZE = [224, 224]
inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in inception.layers:
    layer.trainable = False

x = Flatten()(inception.output)
prediction = Dense(len(folders), activation='sigmoid')(x)

# create a model object
model = Model(inputs=inception.input, outputs=prediction)

model.compile(optimizer = 'adam',
             loss = 'binary_crossentropy',
             metrics=['accuracy'])

history = model.fit(X_train, y_train, validation_split=0.2,
                   epochs = 2,
                   batch_size = 32,
                   verbose = 1)

from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)

from sklearn import metrics

import pandas as pd

res = pd.DataFrame(columns=["Accuracy", 
                            "Precision", 
                            "Recall", 
                            "F1Score"])

ypred = model.predict(X_test)
y_pred = np.round(abs(ypred))
pr, rc, fs, sup = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')
res = res.append({"Accuracy": round(metrics.accuracy_score(y_test, y_pred), 4),"Precision": round(pr, 4), "Recall":round(rc, 4), "F1Score":round(fs, 4),}, ignore_index=True)
res.set_index("Accuracy", inplace=True)
res.sort_values(by="Accuracy", ascending=False, inplace=True)   
print(res)

"""#**VGG19**"""

from tensorflow.keras.applications.vgg19 import VGG19

IMAGE_SIZE = [224, 224]

vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in vgg.layers:
    layer.trainable = False

x1 = Flatten()(vgg.output)

x1= Flatten()(vgg.output)
prediction = Dense(len(folders), activation='sigmoid')(x1)

# create a model object
moddel1 = Model(inputs=vgg.input, outputs=prediction)

moddel1.compile(optimizer = 'adam',
             loss = 'binary_crossentropy',
             metrics=['accuracy'])

history1 = moddel1.fit(X_train, y_train, validation_split=0.2,
                   epochs = 2,
                   batch_size = 32,
                   verbose = 1)

y_pred = moddel1.predict(X_test)
print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))